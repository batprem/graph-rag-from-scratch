{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c175b865",
   "metadata": {},
   "source": [
    "# Set up Nebula 3 connection\n",
    "## Initial a client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd458c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nebula3.gclient.net import ConnectionPool\n",
    "from nebula3.Config import Config\n",
    "from nebula3.gclient.net import Session\n",
    "\n",
    "# Configuration\n",
    "nebula_host = \"127.0.0.1\"  # Replace with your Nebula Graph host\n",
    "nebula_port = 9669  # Replace with your Nebula Graph port\n",
    "username = \"root\"  # Replace with your Nebula Graph username\n",
    "password = \"nebula\"  # Replace with your Nebula Graph password\n",
    "space_name = \"news\"  # Replace with your Nebula Graph space name\n",
    "\n",
    "# Create a configuration object\n",
    "config = Config()\n",
    "config.max_connection_pool_size = 10\n",
    "\n",
    "# Initialize the connection pool\n",
    "connection_pool = ConnectionPool()\n",
    "assert connection_pool.init([(nebula_host, nebula_port)], config), \"Failed to initialize the connection pool\"\n",
    "\n",
    "# Create a session\n",
    "session = connection_pool.get_session(username, password)\n",
    "assert (session := connection_pool.get_session(username, password)), \"Failed to create a session\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1c9dc",
   "metadata": {},
   "source": [
    "## Create Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a291c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space 'news' created and selected successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a space\n",
    "create_space_query = f\"\"\"\n",
    "CREATE SPACE IF NOT EXISTS {space_name} (partition_num=15, replica_factor=1, vid_type=FIXED_STRING(3000));\n",
    "\"\"\"\n",
    "session.execute(create_space_query)\n",
    "print(f\"Space '{space_name}' created and selected successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0843",
   "metadata": {},
   "source": [
    "## Use Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8da8c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the newly created space\n",
    "import time\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    use_space_query = f\"USE {space_name};\"\n",
    "    query_result = session.execute(use_space_query)\n",
    "    if query_result.is_succeeded():\n",
    "        break\n",
    "    time.sleep(5)\n",
    "else:\n",
    "    assert query_result.is_succeeded(), query_result.error_msg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b028aa22",
   "metadata": {},
   "source": [
    "## Create tag `entity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae434b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"USE {space_name}; CREATE tag `entity` (`name` string NULL  ) \"\n",
    "\n",
    "result = session.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8b54441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.error_msg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d0b3e",
   "metadata": {},
   "source": [
    "## Create tag `relationship`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d1b638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResultSet(None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"CREATE edge `relationship` (`relationship` string NOT NULL, source string NOT NULL  ) \"\n",
    "\n",
    "session.execute(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b9c69",
   "metadata": {},
   "source": [
    "## Create index for searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f75dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"CREATE TAG INDEX `enitiy_index` on `entity`(`name`(100)) \"\n",
    "query_result = session.execute(query)\n",
    "assert query_result.is_succeeded(), query_result.error_msg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf9bcb",
   "metadata": {},
   "source": [
    "# Ingest data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09100fb",
   "metadata": {},
   "source": [
    "## News data for BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f324cc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_news: str = \"\"\"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\n",
    "\n",
    "His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\n",
    "He pledged to serve all Americans if elected then recounted, in a subdued, but almost messianic tone, his brush with a spray of bullets. Some delegates even wore bandages over their right ears like their injured political idol in tribute to him.\n",
    "\"I stand before you in this arena only by the grace of almighty God,” he said. “Over the last few days, many people have said it was a providential moment.” He spoke of dropping to the ground as bullets flew past him and how his supporters had “great sorrow on their faces”.\n",
    "“When I rose, surrounded by Secret Service, the crowd was confused because they thought I was dead,” he said.\n",
    "The unity message and its powerful delivery made for a unique convention speech and a remarkable Trump one. But the rest of his speech was more traditional convention fare.\n",
    "Although he called for ending the “partisan witch hunts” against him, he avoided the extended forays into 2020 election denial that have at times dominated his rally speeches, and he mostly replaced his normal pointed attacks on individual opponents with calls for unity.\n",
    "There was classic Trump in there too - dark and false claims, sometimes during extended improvisations.\n",
    "Trump’s performance hinted that for all the talk of a changed man after the attempt on his life and for all the more organised, focused operation behind him, the former president is still inclined to veer off-script, even in the most momentous of occasions.\n",
    "The question many Americans could be wondering now is which version of Trump will lead the country should he beat Democrat Joe Biden in November. Looking back at the last four days offers some clues.\n",
    "\"\"\"\n",
    "# Credit: https://www.bbc.com/news/articles/cqv5y29qnpgo\n",
    "source_bbc = \"https://www.bbc.com/news/articles/cqv5y29qnpgo\"\n",
    "news_list = [line for line in bbc_news.splitlines() if line]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fbfa38",
   "metadata": {},
   "source": [
    "## Know graph extraction\n",
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b0e1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "MODEL = \"qwen2:7b-instruct-q6_K\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6d7616",
   "metadata": {},
   "source": [
    "### Filling the knowledge Graph prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "795b70dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some text is provided below. Given the text, extract up to 20 knowledge triplets in the form of (subject, predicate, object, extracting_area). Avoid stopwords. You must use the given background context as a footnote. Your output must not be extracted from background context\n",
      "---------------------\n",
      "Example:\n",
      "Background context: \"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\"\n",
      "Text: \"His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\"\n",
      "Triplets:\n",
      "{\n",
      "        \"results\": [\n",
      "            [\"Donald Trump\", \"took the stage\", \"on Thursday night at the Republican National Convention\", \"background_context\"],\n",
      "            [\"Donald Trump\", \"cheated death\", \"\", \"background_context\"],\n",
      "            [\"Donald Trump's Democratic opponents\", \"were tearing themselves apart\", \"\", \"background_context\"],\n",
      "            [\"Donald Trump's loyalists\", \"fill\", \"the ranks of Donald Trump's party\", \"text\"],\n",
      "            [\"Donald Trump's loyalists\", \"packed\", \"the Milwaukee arena\", \"text\"],\n",
      "            [\"Donald Trump's loyalists\", \"cheered throughout\", \"Donald Trump's hour-and-a-half speech\", \"text\"],\n",
      "        ]\n",
      "}\n",
      "---------------------\n",
      "Background context: \"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\"\n",
      "Text: \"His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\"\n",
      "Triplets:\n"
     ]
    }
   ],
   "source": [
    "from string import Template\n",
    "\n",
    "DEFAULT_KG_TRIPLET_EXTRACT_TMPL = Template(\"\"\"\n",
    "Some text is provided below. Given the text, extract up to ${max_knowledge_triplets} knowledge triplets in the form of (subject, predicate, object, extracting_area). Avoid stopwords. You must use the given background context as a footnote. Your output must not be extracted from background context\n",
    "---------------------\n",
    "Example:\n",
    "Background context: \"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\"\n",
    "Text: \"His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\"\n",
    "Triplets:\n",
    "{\n",
    "        \"results\": [\n",
    "            [\"Donald Trump\", \"took the stage\", \"on Thursday night at the Republican National Convention\", \"background_context\"],\n",
    "            [\"Donald Trump\", \"cheated death\", \"\", \"background_context\"],\n",
    "            [\"Donald Trump's Democratic opponents\", \"were tearing themselves apart\", \"\", \"background_context\"],\n",
    "            [\"Donald Trump's loyalists\", \"fill\", \"the ranks of Donald Trump's party\", \"text\"],\n",
    "            [\"Donald Trump's loyalists\", \"packed\", \"the Milwaukee arena\", \"text\"],\n",
    "            [\"Donald Trump's loyalists\", \"cheered throughout\", \"Donald Trump's hour-and-a-half speech\", \"text\"],\n",
    "        ]\n",
    "}\n",
    "---------------------\n",
    "${background_context}\n",
    "Text: ${text}\n",
    "Triplets:\"\"\")\n",
    "\n",
    "# DEFAULT_KG_TRIPLET_EXTRACT_TMPL = Template(\"\"\"\n",
    "# Some text is provided below. Given the text, extract up to ${max_knowledge_triplets} knowledge triplets in the form of (subject, predicate, object). Avoid stopwords. You must use the given background context as a footnote. Your output must not be extracted from background context\n",
    "# ---------------------\n",
    "# Example:\n",
    "# Background context: \"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\"\n",
    "# Text: \"His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\"\n",
    "# Triplets:\n",
    "# {\n",
    "#         \"results\": [\n",
    "#             [\"Donald Trump's loyalists\", \"fill\", \"the ranks of Donald Trump's party\"],\n",
    "#             [\"Donald Trump's loyalists\", \"packed\", \"the Milwaukee arena\"],\n",
    "#             [\"Donald Trump's loyalists\", \"cheered throughout\", \"Donald Trump's hour-and-a-half speech\"],\n",
    "#         ]\n",
    "# }\n",
    "# ---------------------\n",
    "# Your turn:\n",
    "# ${background_context}\n",
    "# Text: ${text}\n",
    "# Triplets:\"\"\")\n",
    "\n",
    "def complete_kg_prompt(\n",
    "    text: str, background_context: str = \"\", max_knowledge_triplets: int = 20\n",
    ") -> str:\n",
    "    if background_context:\n",
    "        background_context = \"Background context: \" + f'\"{background_context}\"'\n",
    "    prompt = DEFAULT_KG_TRIPLET_EXTRACT_TMPL.safe_substitute(\n",
    "        text=f'\"{text}\"',\n",
    "        background_context=background_context,\n",
    "        max_knowledge_triplets=max_knowledge_triplets,\n",
    "    )\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "prompt = complete_kg_prompt(\n",
    "    \"His loyalists, who now fill the ranks of his party, packed the Milwaukee arena and cheered enthusiastically throughout his hour-and-a-half speech.\",\n",
    "    \"Donald Trump took the stage on Thursday night at the Republican National Convention like a conquering hero. He had cheated death. His Democratic opponents were tearing themselves apart.\",\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eec0947",
   "metadata": {},
   "source": [
    "### Test extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecea62fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The question', 'many Americans could be wondering now', 'is which version of Trump will lead the country should he beat Democrat Joe Biden in November'), ('Looking back at the last four days', 'offers some clues', 'about the future leadership style of Donald Trump if he wins against Joe Biden')]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import TypedDict\n",
    "from retry import retry as classic_retry\n",
    "\n",
    "\n",
    "class TripetResult(TypedDict):\n",
    "    results: list[tuple[str, str, str]]\n",
    "\n",
    "\n",
    "@classic_retry(tries=5, exceptions=json.JSONDecodeError)\n",
    "def get_tripets(prompt: str) -> list[tuple[str, str, str]]:\n",
    "    response = ollama.generate(prompt=prompt, model=MODEL)[\"response\"]\n",
    "    results = json.loads(response)[\"results\"]\n",
    "    results = [tuple(result) for result in results]\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_kg_tripet(\n",
    "    text: str,\n",
    "    main_context: str = \"\",\n",
    "    max_knowledge_triplets: int = 20,\n",
    "    all_context: bool = False,\n",
    ") -> list[tuple[str, str, str]]:\n",
    "\n",
    "    prompt = complete_kg_prompt(text, main_context, max_knowledge_triplets)\n",
    "    results = get_tripets(prompt)\n",
    "    results = [(*elem,) for *elem, r in results if (r == \"text\") or all_context]\n",
    "    return results\n",
    "\n",
    "\n",
    "response = get_kg_tripet(news_list[-1], news_list[0], 1000)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14c65b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Donald Trump', 'took the stage', 'on Thursday night at the Republican National Convention'), ('Donald Trump', 'cheated death', ''), (\"Donald Trump's Democratic opponents\", 'were tearing themselves apart', '')]\n"
     ]
    }
   ],
   "source": [
    "response = get_kg_tripet(news_list[0], news_list[0], 1000, all_context=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0469457",
   "metadata": {},
   "source": [
    "# Ingest knowledge graph into Nebula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c299fe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, Dict\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "QUOTE = '\"'\n",
    "RETRY_TIMES = 3\n",
    "WAIT_MIN_SECONDS = 0.5\n",
    "WAIT_MAX_SECONDS = 10\n",
    "\n",
    "\n",
    "def escape_str(value: str) -> str:\n",
    "    \"\"\"Escape String for NebulaGraph Query.\"\"\"\n",
    "    patterns = {\n",
    "        '\"': \" \",\n",
    "    }\n",
    "    for pattern in patterns:\n",
    "        if pattern in value:\n",
    "            value = value.replace(pattern, patterns[pattern])\n",
    "\n",
    "    return value.strip()\n",
    "\n",
    "\n",
    "@retry(\n",
    "    wait=wait_random_exponential(min=WAIT_MIN_SECONDS, max=WAIT_MAX_SECONDS),\n",
    "    stop=stop_after_attempt(RETRY_TIMES),\n",
    ")\n",
    "def execute(query: str) -> Any:\n",
    "    \"\"\"Execute query.\n",
    "\n",
    "    Args:\n",
    "        query: Query.\n",
    "        param_map: Parameter map.\n",
    "\n",
    "    Returns:\n",
    "        Query result.\n",
    "    \"\"\"\n",
    "    # Clean the query string by removing triple backticks\n",
    "    query = query.replace(\"```\", \"\").strip()\n",
    "    return session.execute(query)\n",
    "\n",
    "\n",
    "def hash_string_to_rank(string: str) -> int:\n",
    "    # get signed 64-bit hash value\n",
    "    signed_hash = hash(string)\n",
    "\n",
    "    # reduce the hash value to a 64-bit range\n",
    "    mask = (1 << 64) - 1\n",
    "    signed_hash &= mask\n",
    "\n",
    "    # convert the signed hash value to an unsigned 64-bit integer\n",
    "    if signed_hash & (1 << 63):\n",
    "        unsigned_hash = -((signed_hash ^ mask) + 1)\n",
    "    else:\n",
    "        unsigned_hash = signed_hash\n",
    "\n",
    "    return unsigned_hash\n",
    "\n",
    "\n",
    "def upsert_triplet(subj: str, rel: str, obj: str, source: str) -> None:\n",
    "    \"\"\"Add triplet.\"\"\"\n",
    "    # Note, to enable leveraging existing knowledge graph,\n",
    "    # the (triplet -- property graph) mapping\n",
    "    #   makes (n:1) edge_type.prop_name --> triplet.rel\n",
    "    # thus we have to assume rel to be the first edge_type.prop_name\n",
    "    # here in upsert_triplet().\n",
    "    # This applies to the type of entity(tags) with subject and object, too,\n",
    "    # thus we have to assume subj to be the first entity.tag_name\n",
    "\n",
    "    # lower case subj, rel, obj\n",
    "    subj = escape_str(subj)\n",
    "    rel = escape_str(rel)\n",
    "    obj = escape_str(str(obj))\n",
    "\n",
    "    subj_field = f\"{QUOTE}{subj}{QUOTE}\"\n",
    "    obj_field = f\"{QUOTE}{obj}{QUOTE}\"\n",
    "    edge_field = f\"{subj_field}->{obj_field}\"\n",
    "    \n",
    "    subj_value = f'\"{subj}\"' if subj is not None else \"NULL\"\n",
    "    obj_value = f'\"{obj}\"' if obj is not None else \"NULL\"\n",
    "\n",
    "    #     edge_type = self._edge_types[0]\n",
    "    edge_type = \"relationship\"\n",
    "    #     rel_prop_name = self._rel_prop_names[0]\n",
    "    rel_prop_name = \"relationship,\"\n",
    "    #     entity_type = self._tags[0]\n",
    "    entity_type = \"entity\"\n",
    "    rel_hash = hash_string_to_rank(rel)\n",
    "    dml_query = (\n",
    "        f\"INSERT VERTEX `{entity_type}`(name) \"\n",
    "        f\"  VALUES {subj_field}:({subj_value});\"\n",
    "        f\"INSERT VERTEX `{entity_type}`(name) \"\n",
    "        f\"  VALUES {obj_field}:({obj_value});\"\n",
    "        f\"INSERT EDGE `relationship`(`relationship`, `source`) \"\n",
    "        f\"  VALUES \"\n",
    "        f\"{edge_field}\"\n",
    "        f\"@{rel_hash}:({QUOTE}{rel}{QUOTE}, {QUOTE}{source}{QUOTE});\"\n",
    "    )\n",
    "\n",
    "    result = execute(dml_query)\n",
    "\n",
    "\n",
    "    assert (\n",
    "        result and result.is_succeeded()\n",
    "    ), f\"Failed to query: {dml_query} Error msg: {result.error_msg()}\"\n",
    "\n",
    "\n",
    "for i, line in enumerate(news_list):\n",
    "    all_context = i == 0\n",
    "    response = get_kg_tripet(line,  news_list[0], 1000, all_context = all_context)\n",
    "    for tripet in response:\n",
    "        if len(tripet) == 3:\n",
    "            subject, relation, obj = tripet\n",
    "        elif len(tripet) == 2:\n",
    "            subject, relation, obj = (*tripet, None)\n",
    "        else:\n",
    "            print(f\"Error at {tripet}\")\n",
    "            continue\n",
    "        result = upsert_triplet(subject, relation, obj, source_bbc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2bcfe3",
   "metadata": {},
   "source": [
    "# Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d18ea060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'subject': 'Donald Trump'}]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from string import Template\n",
    "\n",
    "CONTEXT_RETRIEVAL = Template(\"\"\"\n",
    "# Instruction:\n",
    "Extract subject, relation and object to query in a graph database to objain information to complete a given task and answer a given question return as an array of JSON\n",
    "\n",
    "# Example:\n",
    "Prompt: \"What's happened to Bob?\"\n",
    "Response:\n",
    "[{\"subject\": \"Bob\"}]\n",
    "\n",
    "# Example:\n",
    "Prompt: \"Write a story about Bob\"\n",
    "Response:\n",
    "[{\"subject\": \"Bob\"}]\n",
    "\n",
    "Prompt: \"Where's Bob going?\"\n",
    "Response:\n",
    "[\n",
    "    {\"subject\": \"Bob\"},\n",
    "    {\"relation\": \"is going\"}\n",
    "]\n",
    "\n",
    "Prompt: \"How do Bob and Ben relate?\"\n",
    "Response:\n",
    "[\n",
    "    {\"subject\": \"Bob\"},\n",
    "    {\"object\": \"Ben\"}\n",
    "]\n",
    "---------\n",
    "# Your turn:\n",
    "Prompt: \"${question}\"\n",
    "Response:\n",
    "\"\"\")\n",
    "\n",
    "user_prompt = \"Write news about Donald Trump\"\n",
    "prompt = CONTEXT_RETRIEVAL.safe_substitute(question=user_prompt)\n",
    "tripets = json.loads(ollama.generate(prompt=prompt, model=MODEL)[\"response\"])\n",
    "print(tripets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a728ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_query(\n",
    "    subject: Optional[str] = None,\n",
    "    relationship: Optional[str] = None,\n",
    "    object_: Optional[str] = None,\n",
    ") -> str:\n",
    "    \"\"\"Get ngql query\n",
    "    # TODO: Add Sanitizing\n",
    "\n",
    "    \"\"\"\n",
    "    conditions: list[str] = []\n",
    "    if subject:\n",
    "        conditions.append(f'LOWER(p.entity.name) CONTAINS LOWER(\"{subject}\")')\n",
    "    if relation:\n",
    "        conditions.append((f'LOWER(r.relationship) CONTAINS LOWER(\"{relation}\")'))\n",
    "    if object_:\n",
    "        conditions.append(f'LOWER(q.entity.name) CONTAINS LOWER(\"{object_}\")')\n",
    "    where_query = \"\\t\"+\" OR\\n\\t\".join(conditions)\n",
    "\n",
    "    query = f\"\"\"\n",
    "MATCH (p:entity)-[r:relationship]->(q:entity)\n",
    "WHERE (\n",
    "    {where_query}\n",
    ")\n",
    "RETURN p.entity.name AS subject,r.relationship AS relationship, q.entity.name AS object;\n",
    "\"\"\"\n",
    "    return query\n",
    "\n",
    "\n",
    "def run_query(space: str, query: str):\n",
    "\n",
    "    # Use the space\n",
    "    session.execute(f\"USE {space}\")\n",
    "\n",
    "    # Execute the query\n",
    "    result = session.execute(query)\n",
    "\n",
    "    # Check if the query was successful\n",
    "    if not result.is_succeeded():\n",
    "        raise ValueError(\"Query failed: {}\".format(result.error_msg()))\n",
    "\n",
    "    # Process the results\n",
    "    return result.as_data_frame()\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for tripet in tripets:\n",
    "    query = get_query(**tripet)\n",
    "    result = run_query(\"news\", query)\n",
    "    results = pd.concat([results, result]).reset_index(drop=True)\n",
    "    \n",
    "results.replace(\"None\", value=\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "340b5eb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>relationship</th>\n",
       "      <th>object</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump's speech</td>\n",
       "      <td>was more traditional convention fare</td>\n",
       "      <td></td>\n",
       "      <td>Donald Trump's speech was more traditional con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump's Democratic opponents</td>\n",
       "      <td>were tearing themselves apart</td>\n",
       "      <td></td>\n",
       "      <td>Donald Trump's Democratic opponents were teari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump's loyalists</td>\n",
       "      <td>fill</td>\n",
       "      <td>the ranks of Donald Trump's party</td>\n",
       "      <td>Donald Trump's loyalists fill the ranks of Don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Donald Trump's loyalists</td>\n",
       "      <td>cheered throughout</td>\n",
       "      <td>Donald Trump's hour-and-a-half speech</td>\n",
       "      <td>Donald Trump's loyalists cheered throughout Do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donald Trump's loyalists</td>\n",
       "      <td>packed</td>\n",
       "      <td>the Milwaukee arena</td>\n",
       "      <td>Donald Trump's loyalists packed the Milwaukee ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               subject                          relationship  \\\n",
       "0                Donald Trump's speech  was more traditional convention fare   \n",
       "1  Donald Trump's Democratic opponents         were tearing themselves apart   \n",
       "2             Donald Trump's loyalists                                  fill   \n",
       "3             Donald Trump's loyalists                    cheered throughout   \n",
       "4             Donald Trump's loyalists                                packed   \n",
       "\n",
       "                                  object  \\\n",
       "0                                          \n",
       "1                                          \n",
       "2      the ranks of Donald Trump's party   \n",
       "3  Donald Trump's hour-and-a-half speech   \n",
       "4                    the Milwaukee arena   \n",
       "\n",
       "                                             context  \n",
       "0  Donald Trump's speech was more traditional con...  \n",
       "1  Donald Trump's Democratic opponents were teari...  \n",
       "2  Donald Trump's loyalists fill the ranks of Don...  \n",
       "3  Donald Trump's loyalists cheered throughout Do...  \n",
       "4  Donald Trump's loyalists packed the Milwaukee ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72c27f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"context\"] = results[\"subject\"] + \" \" + results[\"relationship\"] + \" \" + results[\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7e94593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"- \" + \"\\n- \".join(results[\"context\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1226ea78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump's speech at the Republican National Convention was more traditional in nature, focusing on calls for unity and service to all Americans rather than his usual pointed attacks on opponents. His loyalists cheered throughout the hour-and-a-half address, filling the Milwaukee arena with their support. The event offered insights into which version of Trump might lead the country if he wins against Democratic nominee Joe Biden in November. He mentioned overcoming a brush with death and called for an end to \"partisan witch hunts,\" emphasizing a more conciliatory tone than his past rally speeches. Despite some sorrow among supporters, the atmosphere was generally supportive, with many attendees expressing their gratitude for Trump's leadership."
     ]
    }
   ],
   "source": [
    "USER_PROXY = Template(\"\"\"\n",
    "# Instruction:\n",
    "You are a user assistant. Please response user's request. You must return the output only and do not include prologue, prefix and suffix\n",
    "\n",
    "# Supporting contexts:\n",
    "${context}\n",
    "\"\"\")\n",
    "\n",
    "user_proxy_prompt = USER_PROXY.safe_substitute(context = context)\n",
    "\n",
    "response = ollama.generate(prompt=user_proxy_prompt, model=MODEL, stream=True)\n",
    "\n",
    "response_text = \"\"\n",
    "for r in response:\n",
    "    c = r[\"response\"]\n",
    "    response_text += c\n",
    "    print(c, end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "196c47b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Donald Trump's speech at the Republican National Convention was more traditional in nature, focusing on calls for unity and service to all Americans rather than his usual pointed attacks on opponents. His loyalists cheered throughout the hour-and-a-half address, filling the Milwaukee arena with their support. The event offered insights into which version of Trump might lead the country if he wins against Democratic nominee Joe Biden in November. He mentioned overcoming a brush with death and called for an end to \"partisan witch hunts,\" emphasizing a more conciliatory tone than his past rally speeches. Despite some sorrow among supporters, the atmosphere was generally supportive, with many attendees expressing their gratitude for Trump's leadership."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "567e6849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donald Trump's speech at the Republican National Convention was a departure from his usual style, focusing more on traditional fare and calls for unity rather than personal attacks. His loyalists, who filled the Milwaukee arena, were enthusiastic throughout the hour-and-a-half address. With polls showing Donald Trump's Democratic opponent tearing herself apart, this speech offered clues about how he might lead the country if re-elected in November. Notably, Trump mentioned surviving a brush with death and called for an end to partisan witch hunts against him. He also spoke of dropping to his knees as bullets flew past him, emphasizing his reliance on God's grace. While at times, he avoided extended discussions about election denial that have been present in previous rally speeches, focusing instead on serving all Americans and acknowledging this moment as providential."
     ]
    }
   ],
   "source": [
    "user_prompt = \"Write a report about Donald Trump\"\n",
    "prompt = CONTEXT_RETRIEVAL.safe_substitute(question=user_prompt)\n",
    "tripets = json.loads(ollama.generate(prompt=prompt, model=MODEL)[\"response\"])\n",
    "\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for tripet in tripets:\n",
    "    query = get_query(**tripet)\n",
    "    result = run_query(\"news\", query)\n",
    "    results = pd.concat([results, result]).reset_index(drop=True)\n",
    "    \n",
    "results.replace(\"None\", value=\"\", inplace=True)\n",
    "\n",
    "user_proxy_prompt = USER_PROXY.safe_substitute(context = context)\n",
    "\n",
    "response = ollama.generate(prompt=user_proxy_prompt, model=MODEL, stream=True)\n",
    "\n",
    "for r in response:\n",
    "    print(r[\"response\"], end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
